{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ddim官方源码分析\n",
    "[ddim](https://github.com/ermongroup/ddim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device=\"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\beta_t \\in(0,1)$ 的计算方式\n",
    "\n",
    "取值范围在(0,1),随着time_step逐步递增"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use: linear\n",
      "[0.0001     0.00030101 0.00050202 0.00070303 0.00090404 0.00110505\n",
      " 0.00130606 0.00150707 0.00170808 0.00190909 0.0021101  0.00231111\n",
      " 0.00251212 0.00271313 0.00291414 0.00311515 0.00331616 0.00351717\n",
      " 0.00371818 0.00391919 0.0041202  0.00432121 0.00452222 0.00472323\n",
      " 0.00492424 0.00512525 0.00532626 0.00552727 0.00572828 0.00592929\n",
      " 0.0061303  0.00633131 0.00653232 0.00673333 0.00693434 0.00713535\n",
      " 0.00733636 0.00753737 0.00773838 0.00793939 0.0081404  0.00834141\n",
      " 0.00854242 0.00874343 0.00894444 0.00914545 0.00934646 0.00954747\n",
      " 0.00974848 0.00994949 0.01015051 0.01035152 0.01055253 0.01075354\n",
      " 0.01095455 0.01115556 0.01135657 0.01155758 0.01175859 0.0119596\n",
      " 0.01216061 0.01236162 0.01256263 0.01276364 0.01296465 0.01316566\n",
      " 0.01336667 0.01356768 0.01376869 0.0139697  0.01417071 0.01437172\n",
      " 0.01457273 0.01477374 0.01497475 0.01517576 0.01537677 0.01557778\n",
      " 0.01577879 0.0159798  0.01618081 0.01638182 0.01658283 0.01678384\n",
      " 0.01698485 0.01718586 0.01738687 0.01758788 0.01778889 0.0179899\n",
      " 0.01819091 0.01839192 0.01859293 0.01879394 0.01899495 0.01919596\n",
      " 0.01939697 0.01959798 0.01979899 0.02      ]\n",
      "Use: const\n",
      "[0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02]\n",
      "Use: jsd\n",
      "[0.01       0.01010101 0.01020408 0.01030928 0.01041667 0.01052632\n",
      " 0.0106383  0.01075269 0.01086957 0.01098901 0.01111111 0.01123596\n",
      " 0.01136364 0.01149425 0.01162791 0.01176471 0.01190476 0.01204819\n",
      " 0.01219512 0.01234568 0.0125     0.01265823 0.01282051 0.01298701\n",
      " 0.01315789 0.01333333 0.01351351 0.01369863 0.01388889 0.01408451\n",
      " 0.01428571 0.01449275 0.01470588 0.01492537 0.01515152 0.01538462\n",
      " 0.015625   0.01587302 0.01612903 0.01639344 0.01666667 0.01694915\n",
      " 0.01724138 0.01754386 0.01785714 0.01818182 0.01851852 0.01886792\n",
      " 0.01923077 0.01960784 0.02       0.02040816 0.02083333 0.0212766\n",
      " 0.02173913 0.02222222 0.02272727 0.02325581 0.02380952 0.02439024\n",
      " 0.025      0.02564103 0.02631579 0.02702703 0.02777778 0.02857143\n",
      " 0.02941176 0.03030303 0.03125    0.03225806 0.03333333 0.03448276\n",
      " 0.03571429 0.03703704 0.03846154 0.04       0.04166667 0.04347826\n",
      " 0.04545455 0.04761905 0.05       0.05263158 0.05555556 0.05882353\n",
      " 0.0625     0.06666667 0.07142857 0.07692308 0.08333333 0.09090909\n",
      " 0.1        0.11111111 0.125      0.14285714 0.16666667 0.2\n",
      " 0.25       0.33333333 0.5        1.        ]\n",
      "Use: sigmoid\n",
      "[0.00014921 0.00015553 0.00016266 0.00017071 0.00017978 0.00019002\n",
      " 0.00020156 0.00021457 0.00022924 0.00024577 0.0002644  0.00028539\n",
      " 0.00030903 0.00033564 0.0003656  0.00039932 0.00043723 0.00047986\n",
      " 0.00052776 0.00058155 0.00064191 0.00070961 0.00078546 0.00087037\n",
      " 0.00096533 0.00107139 0.00118972 0.00132152 0.00146811 0.00163085\n",
      " 0.00181116 0.0020105  0.00223034 0.00247214 0.00273731 0.00302717\n",
      " 0.00334291 0.00368551 0.00405571 0.00445394 0.00488023 0.0053342\n",
      " 0.005815   0.00632122 0.00685095 0.0074017  0.00797049 0.00855386\n",
      " 0.00914794 0.00974858 0.01035142 0.01095206 0.01154614 0.01212951\n",
      " 0.0126983  0.01324905 0.01377878 0.014285   0.0147658  0.01521977\n",
      " 0.01564606 0.01604429 0.01641449 0.01675709 0.01707283 0.01736269\n",
      " 0.01762786 0.01786966 0.0180895  0.01828884 0.01846915 0.01863189\n",
      " 0.01877848 0.01891028 0.01902861 0.01913467 0.01922963 0.01931454\n",
      " 0.01939039 0.01945809 0.01951845 0.01957224 0.01962014 0.01966277\n",
      " 0.01970068 0.0197344  0.01976436 0.01979097 0.01981461 0.0198356\n",
      " 0.01985423 0.01987076 0.01988543 0.01989844 0.01990998 0.01992022\n",
      " 0.01992929 0.01993734 0.01994447 0.01995079]\n"
     ]
    }
   ],
   "source": [
    "# $\\beta_t \\in(0,1)$ 的计算方式\n",
    "def get_beta_schedule(beta_schedule, *, beta_start, beta_end, num_diffusion_timesteps):\n",
    "    print(\"Use:\",beta_schedule)\n",
    "    def sigmoid(x):\n",
    "        return 1 / (np.exp(-x) + 1)\n",
    "\n",
    "    if beta_schedule == \"quad\":\n",
    "        betas = (\n",
    "            np.linspace(\n",
    "                beta_start ** 0.5,\n",
    "                beta_end ** 0.5,\n",
    "                num_diffusion_timesteps,\n",
    "                dtype=np.float64,\n",
    "            )\n",
    "            ** 2\n",
    "        )\n",
    "    elif beta_schedule == \"linear\":\n",
    "        betas = np.linspace(\n",
    "            beta_start, beta_end, num_diffusion_timesteps, dtype=np.float64\n",
    "        )\n",
    "    elif beta_schedule == \"const\":\n",
    "        betas = beta_end * np.ones(num_diffusion_timesteps, dtype=np.float64)\n",
    "    elif beta_schedule == \"jsd\":  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n",
    "        betas = 1.0 / np.linspace(\n",
    "            num_diffusion_timesteps, 1, num_diffusion_timesteps, dtype=np.float64\n",
    "        )\n",
    "    elif beta_schedule == \"sigmoid\":\n",
    "        betas = np.linspace(-6, 6, num_diffusion_timesteps)\n",
    "        betas = sigmoid(betas) * (beta_end - beta_start) + beta_start\n",
    "    else:\n",
    "        raise NotImplementedError(beta_schedule)\n",
    "    assert betas.shape == (num_diffusion_timesteps,)\n",
    "    return betas\n",
    "\n",
    "\n",
    "beta_start = 0.0001\n",
    "beta_end = 0.02\n",
    "num_diffusion_timesteps = 100 #论文是1000，为了方便测试观察取100\n",
    "\n",
    "beta_schedule = \"linear\"\n",
    "betas = get_beta_schedule(\n",
    "            beta_schedule=beta_schedule,\n",
    "            beta_start=beta_start,\n",
    "            beta_end=beta_end,\n",
    "            num_diffusion_timesteps=num_diffusion_timesteps,\n",
    "        )\n",
    "print(betas)\n",
    "\n",
    "\n",
    "beta_schedule = \"const\"\n",
    "betas = get_beta_schedule(\n",
    "            beta_schedule=beta_schedule,\n",
    "            beta_start=beta_start,\n",
    "            beta_end=beta_end,\n",
    "            num_diffusion_timesteps=num_diffusion_timesteps,\n",
    "        )\n",
    "print(betas)\n",
    "\n",
    "\n",
    "beta_schedule = \"jsd\"\n",
    "betas = get_beta_schedule(\n",
    "            beta_schedule=beta_schedule,\n",
    "            beta_start=beta_start,\n",
    "            beta_end=beta_end,\n",
    "            num_diffusion_timesteps=num_diffusion_timesteps,\n",
    "        )\n",
    "print(betas)\n",
    "\n",
    "\n",
    "beta_schedule = \"sigmoid\"\n",
    "betas = get_beta_schedule(\n",
    "            beta_schedule=beta_schedule,\n",
    "            beta_start=beta_start,\n",
    "            beta_end=beta_end,\n",
    "            num_diffusion_timesteps=num_diffusion_timesteps,\n",
    "        )\n",
    "print(betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alphas: tensor([0.9999, 0.9998, 0.9998, 0.9998, 0.9998, 0.9998, 0.9998, 0.9998, 0.9998,\n",
      "        0.9998, 0.9997, 0.9997, 0.9997, 0.9997, 0.9996, 0.9996, 0.9996, 0.9995,\n",
      "        0.9995, 0.9994, 0.9994, 0.9993, 0.9992, 0.9991, 0.9990, 0.9989, 0.9988,\n",
      "        0.9987, 0.9985, 0.9984, 0.9982, 0.9980, 0.9978, 0.9975, 0.9973, 0.9970,\n",
      "        0.9967, 0.9963, 0.9959, 0.9955, 0.9951, 0.9947, 0.9942, 0.9937, 0.9931,\n",
      "        0.9926, 0.9920, 0.9914, 0.9909, 0.9903, 0.9896, 0.9890, 0.9885, 0.9879,\n",
      "        0.9873, 0.9868, 0.9862, 0.9857, 0.9852, 0.9848, 0.9844, 0.9840, 0.9836,\n",
      "        0.9832, 0.9829, 0.9826, 0.9824, 0.9821, 0.9819, 0.9817, 0.9815, 0.9814,\n",
      "        0.9812, 0.9811, 0.9810, 0.9809, 0.9808, 0.9807, 0.9806, 0.9805, 0.9805,\n",
      "        0.9804, 0.9804, 0.9803, 0.9803, 0.9803, 0.9802, 0.9802, 0.9802, 0.9802,\n",
      "        0.9801, 0.9801, 0.9801, 0.9801, 0.9801, 0.9801, 0.9801, 0.9801, 0.9801,\n",
      "        0.9800], device='cuda:0')\n",
      "alphas_cumprod: tensor([0.9999, 0.9997, 0.9995, 0.9994, 0.9992, 0.9990, 0.9988, 0.9986, 0.9983,\n",
      "        0.9981, 0.9978, 0.9976, 0.9972, 0.9969, 0.9965, 0.9961, 0.9957, 0.9952,\n",
      "        0.9947, 0.9941, 0.9935, 0.9928, 0.9920, 0.9911, 0.9902, 0.9891, 0.9880,\n",
      "        0.9866, 0.9852, 0.9836, 0.9818, 0.9798, 0.9776, 0.9752, 0.9726, 0.9696,\n",
      "        0.9664, 0.9628, 0.9589, 0.9546, 0.9500, 0.9449, 0.9394, 0.9335, 0.9271,\n",
      "        0.9202, 0.9129, 0.9051, 0.8968, 0.8881, 0.8789, 0.8692, 0.8592, 0.8488,\n",
      "        0.8380, 0.8269, 0.8155, 0.8039, 0.7920, 0.7799, 0.7677, 0.7554, 0.7430,\n",
      "        0.7306, 0.7181, 0.7056, 0.6932, 0.6808, 0.6685, 0.6563, 0.6441, 0.6321,\n",
      "        0.6203, 0.6085, 0.5970, 0.5855, 0.5743, 0.5632, 0.5523, 0.5415, 0.5309,\n",
      "        0.5206, 0.5103, 0.5003, 0.4904, 0.4808, 0.4713, 0.4619, 0.4528, 0.4438,\n",
      "        0.4350, 0.4264, 0.4179, 0.4096, 0.4014, 0.3934, 0.3856, 0.3779, 0.3703,\n",
      "        0.3630], device='cuda:0')\n",
      "alphas_cumprod_prev: tensor([1.0000, 0.9999, 0.9997, 0.9995, 0.9994, 0.9992, 0.9990, 0.9988, 0.9986,\n",
      "        0.9983, 0.9981, 0.9978, 0.9976, 0.9972, 0.9969, 0.9965, 0.9961, 0.9957,\n",
      "        0.9952, 0.9947, 0.9941, 0.9935, 0.9928, 0.9920, 0.9911, 0.9902, 0.9891,\n",
      "        0.9880, 0.9866, 0.9852, 0.9836, 0.9818, 0.9798, 0.9776, 0.9752, 0.9726,\n",
      "        0.9696, 0.9664, 0.9628, 0.9589, 0.9546, 0.9500, 0.9449, 0.9394, 0.9335,\n",
      "        0.9271, 0.9202, 0.9129, 0.9051, 0.8968, 0.8881, 0.8789, 0.8692, 0.8592,\n",
      "        0.8488, 0.8380, 0.8269, 0.8155, 0.8039, 0.7920, 0.7799, 0.7677, 0.7554,\n",
      "        0.7430, 0.7306, 0.7181, 0.7056, 0.6932, 0.6808, 0.6685, 0.6563, 0.6441,\n",
      "        0.6321, 0.6203, 0.6085, 0.5970, 0.5855, 0.5743, 0.5632, 0.5523, 0.5415,\n",
      "        0.5309, 0.5206, 0.5103, 0.5003, 0.4904, 0.4808, 0.4713, 0.4619, 0.4528,\n",
      "        0.4438, 0.4350, 0.4264, 0.4179, 0.4096, 0.4014, 0.3934, 0.3856, 0.3779,\n",
      "        0.3703], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "betas  = torch.from_numpy(betas).float().to(device)\n",
    "num_timesteps = betas.shape[0]\n",
    "alphas = 1.0 - betas\n",
    "alphas_cumprod = alphas.cumprod(dim=0)\n",
    "alphas_cumprod_prev = torch.cat(\n",
    "    [torch.ones(1).to(device), alphas_cumprod[:-1]], dim=0\n",
    ") #这个地方直接在index=0的位置 放了1，做补位。\n",
    "\n",
    "print(\"alphas:\",alphas)\n",
    "print(\"alphas_cumprod:\",alphas_cumprod)\n",
    "print(\"alphas_cumprod_prev:\",alphas_cumprod_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.训练和DDPM保持不变\n",
    "\n",
    "2.采用的公式变了，原来需要1000 steps，现在50个step就可以了，也就是中间可以跳过去。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd-webui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
